{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE6uZwVbKoH6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# reading the CSV file\n",
        "file = 'breast-cancer-wisconsin-data/data.csv'\n",
        "newData = pd.read_csv(file)\n",
        "\n",
        "# displaying the contents of the CSV file\n",
        "newData.head()\n",
        "\n",
        "newData.info()\n",
        "newData.describe()\n",
        "# **clean data which are unused**\n",
        "sns.heatmap(newData.isnull())\n",
        "newData.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)#axis 1 for column and 0 for row both are colm\n",
        "data=newData\n",
        "data.head()\n",
        "data.diagnosis=[1 if value == \"M\" else 0 for value in data.diagnosis]\n",
        "data.head()\n",
        "data[\"diagnosis\"]=data['diagnosis'].astype(\"category\",copy=False) # to convert diagnosis into category type that 0 & 1 is not integer here it is category that cancer is malignant or not\n",
        "data[\"diagnosis\"].value_counts().plot(kind=\"bar\")\n",
        "data.diagnosis# target column\n",
        "#**Divide into target variable and predictors**\n",
        "y=data[\"diagnosis\"]\n",
        "x=data.drop([\"diagnosis\"],axis=1) # not modified in actual data set\n",
        "x\n",
        "\n",
        "y\n",
        "##**now we are doing normalization bcz some values are near to around11-20 some are above 100 and same are near to 0 ,to make it simplified**\n",
        "## **Normalize the data**\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#create a scaler object\n",
        "scaler=StandardScaler()\n",
        "\n",
        "#fit the scaler to the data and transform the data\n",
        "x_scaled=scaler.fit_transform(x)\n",
        "\n",
        "x_scaled\n",
        "## **split the data**\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.30,random_state=42)\n",
        "## **Train the model**\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#create lr model\n",
        "lr=LogisticRegression()\n",
        "#train the model with training data\n",
        "\n",
        "lr.fit(x_train,y_train)\n",
        "\n",
        "#predict the target variable on test data\n",
        "y_pred=lr.predict(x_test)\n",
        "y_pred\n",
        "y_test\n",
        "## **Evaluation of the model**\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acrcy=accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(f\"Accuracy of model:{acrcy:.2f}\")\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
